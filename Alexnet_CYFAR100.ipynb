{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet_CYFAR100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNP2uzdZzvIZK/YgNiCWlUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ulisses-adonis/.Artificial-neural-network--projects/blob/main/Alexnet_CYFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4K90EoGQt6U"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras.datasets import cifar10, cifar100\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZSKGbeYQ7M-"
      },
      "source": [
        "np.random.seed(1000)\n",
        "(X_train10, Y_train10), (X_test10, Y_test10) = cifar10.load_data()\n",
        "(X_train100, Y_train100), (X_test100, Y_test100) = cifar100.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DINdMitGEhpj"
      },
      "source": [
        "Um dos problemas de aplicar o AlexNet diretamente no dataset CIFAR-10 ou CIFAR100 é que as  imagens desses dois conjunto de imagens,  têm resolução inferior (32 × 32 pixels) em relação as imagens usadas no dataset original (Image Net), para qual a AlexNet foi proposta . Para fazer as coisas funcionarem, deveríamos aumentar a resolução da amostra para 224 × 224 pixels (geralmente não é uma prática inteligente, mas faríamos isso para sermos fiéis à arquitetura AlexNet). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MrWYJQEQ7Ph"
      },
      "source": [
        "alexnet = Sequential()\n",
        "\n",
        "# Layer 1\n",
        "alexnet.add(Conv2D(96, (3, 3), input_shape=(32, 32, 3),\n",
        " padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Layer 2\n",
        "alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Layer 3\n",
        "alexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Layer 6\n",
        "alexnet.add(Flatten())\n",
        "alexnet.add(Dense(4096))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('relu'))\n",
        "alexnet.add(Dropout(0.5))\n",
        "# Layer 8\n",
        "alexnet.add(Dense(100))\n",
        "alexnet.add(BatchNormalization())\n",
        "alexnet.add(Activation('softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlTBwiqEyJd"
      },
      "source": [
        "O tamanho do lote (batch_size) é um dos hiperparâmetros mais importantes para sintonizar os modernos sistemas de aprendizagem profunda. Os Cientistas de Dados muitas vezes querem usar um tamanho de lote maior para treinar seu modelo, uma vez que permite acelerações computacionais do paralelismo das GPUs. No entanto, é bem conhecido que um tamanho de lote muito grande levará a uma generalização deficiente (embora atualmente não se saiba exatamente porque isso acontece). \tNo caso  com um bacth_size =64, para  5 épocas , o modelo obteve uma precisão melhor do que para um batch_size = 128 e 10 épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5GySGfNQ7Sq",
        "outputId": "46771f08-0f1c-4244-90be-5b5dcedfb395"
      },
      "source": [
        "alexnet.compile(loss='categorical_crossentropy',\n",
        " optimizer=Adam(lr=0.0001),\n",
        " metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htcf7Sjk2JkV",
        "outputId": "eeddc447-9d70-4af2-b34b-8d908520eea3"
      },
      "source": [
        "alexnet.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 96)        2688      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               409700    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 35,785,972\n",
            "Trainable params: 35,775,852\n",
            "Non-trainable params: 10,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gbAYjcIFNrV"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oezBwtl4Q7Vl",
        "outputId": "e691d035-c246-4585-fd40-744e59c1246c"
      },
      "source": [
        "#(X_train100, Y_train100), (X_test100, Y_test100) = cifar100.load_data()\n",
        "#alexnet.fit(X_train10 / 255.0, to_categorical(Y_train10),\n",
        "alexnet.fit(X_train100 / 255.0, to_categorical(Y_train100),\n",
        " batch_size=64,\n",
        " shuffle=True,\n",
        " epochs=10,\n",
        "#validation_data=(X_test10 / 255.0, to_categorical(Y_test10)))\n",
        "validation_data=(X_test100/ 255.0, to_categorical(Y_test100)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 40s 29ms/step - loss: 3.7235 - accuracy: 0.1661 - val_loss: 2.9423 - val_accuracy: 0.3313\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 2.7455 - accuracy: 0.3767 - val_loss: 2.6108 - val_accuracy: 0.4123\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 2.3505 - accuracy: 0.4852 - val_loss: 2.3884 - val_accuracy: 0.4510\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 2.0381 - accuracy: 0.5707 - val_loss: 2.2968 - val_accuracy: 0.4851\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.7265 - accuracy: 0.6726 - val_loss: 2.3567 - val_accuracy: 0.4788\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.4572 - accuracy: 0.7587 - val_loss: 2.2892 - val_accuracy: 0.4954\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 1.1936 - accuracy: 0.8412 - val_loss: 2.2022 - val_accuracy: 0.5027\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 0.9698 - accuracy: 0.8937 - val_loss: 2.2401 - val_accuracy: 0.5057\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 0.8001 - accuracy: 0.9303 - val_loss: 2.2675 - val_accuracy: 0.4913\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 0.6689 - accuracy: 0.9528 - val_loss: 2.2638 - val_accuracy: 0.5040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e8f3ef910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1m-lPFEKvOG"
      },
      "source": [
        "Os valores de accuracy e val_accuracy diferem porque o primeiro é aplicado ao conjunto de treino e o último ao conjunto de teste.  Em resumo, accuracy é a precisão de um lote de dados de treinamento e val_acc é a precisão de um lote de dados de teste.\n",
        "Como tal, o último é uma boa indicação do desempenhodo modelo em dados não vistos.  É melhor contar com val_acc para uma representação justa do desempenho do modelo porque uma boa rede neural acabará ajustando os dados de treinamento a 100%, mas teria um desempenho insatisfatório em dados invisíveis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf-DEguQ7YJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fb4784-c4ea-4a14-d6eb-25aa1663ffaa"
      },
      "source": [
        "scores = alexnet.evaluate(X_test100 / 255.0, to_categorical(Y_test100))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 2.2638 - accuracy: 0.5039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpIb065uFTf_",
        "outputId": "d2ad4d89-b427-4a93-c3cd-a17a4b485e7d"
      },
      "source": [
        "print('Loss: %.3f' % scores[0])\n",
        "print('Accuracy: %.3f' % scores[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.264\n",
            "Accuracy: 0.504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waWCR05g5kdw"
      },
      "source": [
        " **Rede com  batch_size = 128**   \n",
        "\n",
        " Loss: 2.645 Accuracy: 0.402\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phAbEWgEFqDm"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIyO2uZbFqGv"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2_KjeiGFqJl"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}